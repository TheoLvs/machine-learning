{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"C:/data/text_generation/songdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(list(dataset.text.head(1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 1170215\n",
      "total chars: 76\n"
     ]
    }
   ],
   "source": [
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 390059\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "688s - loss: 1.6448\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" thank you very much\n",
      "\n",
      " Enough's enough's\"\n",
      " thank you very much\n",
      "\n",
      " Enough's enough's the morning  \n",
      "And I say  \n",
      "  \n",
      "I was the morning the morning  \n",
      "And I say  \n",
      "I was a little bother the more  \n",
      "And I was the morning the rain  \n",
      "I was the too man  \n",
      "And I can see you the money  \n",
      "I was a little only with the morning  \n",
      "And the morning the dark with my way  \n",
      "I was the morning the more  \n",
      "I say  \n",
      "  \n",
      "I start the night that I was the morning  \n",
      "And I say  \n",
      "  \n",
      "I was the part the morning  \n",
      "I was\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" thank you very much\n",
      "\n",
      " Enough's enough's\"\n",
      " thank you very much\n",
      "\n",
      " Enough's enough's what you don't make me but my breaded  \n",
      "She going by the mind  \n",
      "I was that be my best my fall  \n",
      "I want to me  \n",
      "  \n",
      "She crazy but it everything the man  \n",
      "We got to see you still  \n",
      "And I can get it in the dame  \n",
      "And I don't get to sleep  \n",
      "I say  \n",
      "  \n",
      "We let you wouldn't be that we fall the learn  \n",
      "And I make a be the bare  \n",
      "Ang fell you song and the backing when I don't let you see in the good  \n",
      "That\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" thank you very much\n",
      "\n",
      " Enough's enough's\"\n",
      " thank you very much\n",
      "\n",
      " Enough's enough's helling wsles tha fell than the shongter  \n",
      "bure the pane, air't I cauie?  \n",
      "Take you sen with the realars place  \n",
      "To take me with me danting you  \n",
      "Ander, bua houck lith a garl withing for other that baby  \n",
      "fartung plecrustormore  \n",
      "  \n",
      "Chrange to she downst and I'm gring alone  \n",
      "I'm right in me the treetce (knoe and small  \n",
      "Feelly haw abouthing in \n",
      "nife is a zomer side creid  \n",
      "  \n",
      "I have to fall theo\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" thank you very much\n",
      "\n",
      " Enough's enough's\"\n",
      " thank you very much\n",
      "\n",
      " Enough's enough's gonta dand  \n",
      "With overing pressile  \n",
      "Some this ouf , give geat a life  \n",
      "A tlat late in love Could, JusnJypas man to you workn fatnne, yeah  \n",
      "Glad'ad, shea I puenpanbe' of my hee?  \n",
      "  \n",
      "I need it uhonly never friend  \n",
      "Oh I wanter owness  \n",
      "Around truub, I'm carsedhazedown't ime beter seaistong I was you freed  \n",
      "I shourdsome girl at amared The btel  \n",
      "Tunules I was the tope( \n",
      "  \n",
      "Glina rifly, our mett \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "685s - loss: 1.4470\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"let go  \n",
      "Don't need no wedding with a sh\"\n",
      "let go  \n",
      "Don't need no wedding with a shore  \n",
      "And I should the sun  \n",
      "I can see the side  \n",
      "  \n",
      "I wanna see the time  \n",
      "I wanna live the side  \n",
      "And I was the time that I was so man  \n",
      "And I can see the way that you think I wanna let you and the fight  \n",
      "I wanna live and man stand  \n",
      "I wanna let you like a little  \n",
      "I was the sun  \n",
      "And I see the side in the side  \n",
      "I wanna see the sun  \n",
      "And I wanna live in the same  \n",
      "She's a time that you want to\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"let go  \n",
      "Don't need no wedding with a sh\"\n",
      "let go  \n",
      "Don't need no wedding with a shine  \n",
      "I don't know it's always to the way  \n",
      "And I away)  \n",
      "Hey a same and morning  \n",
      "But I know you ever be  \n",
      "But we can do  \n",
      "I tried the street  \n",
      "  \n",
      "I feel the bats that killing me  \n",
      "I am thing the powing man  \n",
      "Can't let the shope and the star the passing door  \n",
      "Lord to have that he say  \n",
      "And I am to you  \n",
      "And I was not the way that I wanna love  \n",
      "I'm done and the side  \n",
      "I don't think I'm too manin\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"let go  \n",
      "Don't need no wedding with a sh\"\n",
      "let go  \n",
      "Don't need no wedding with a shame  \n",
      "untrippet good, own the way  \n",
      "I found your parign steaded astasil timy place an thing  \n",
      "  \n",
      "Pig bustatay dayiWin' and brokeg  \n",
      "Take ovilgriau, wasn't smile, oplas how never song not you world, so hand  \n",
      "Living down and rost  \n",
      "Ceave I've becauded around to lave  \n",
      "I feel your kness of my ercorol.  \n",
      "All will be so clan to lover  \n",
      "Ruspin' trust donat it's one time one  \n",
      "A'faod long an nave you la\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"let go  \n",
      "Don't need no wedding with a sh\"\n",
      "let go  \n",
      "Don't need no wedding with a shoesid tetrine was mes inside  \n",
      "laud's mearing on you  \n",
      "  \n",
      "Share sole that's jusn a kishd  \n",
      "I look some neamin' eller.. that them smove la gift is rairaledben .  \n",
      "So  \n",
      "Neat thruat if my own  \n",
      "  \n",
      "Tutree in my my staatido tish  \n",
      "  \n",
      "Spinah, a ried, year on with (Thanks ave gone s me  \n",
      "Wh twear,'s unnnice of time uped  \n",
      "Away\n",
      "\n",
      " My dearmorr - bard the jobneh thlas polechkneer,  \n",
      "I'm voubight thinrs give \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "712s - loss: 1.3949\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"world, one love, these can never be apar\"\n",
      "world, one love, these can never be apart  \n",
      "And I want to be the stars  \n",
      "And I want to be all the things  \n",
      "And the way that I said  \n",
      "I'm still the sound  \n",
      "I want to she was strange  \n",
      "So she was all the time  \n",
      "I want to be the start  \n",
      "I want to the with you  \n",
      "And I want to love you  \n",
      "I want to be all the stars  \n",
      "I want to the shore you can  \n",
      "I'm so find  \n",
      "And I can do me  \n",
      "There is all the morning  \n",
      "I can see the part  \n",
      "And when I can be\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"world, one love, these can never be apar\"\n",
      "world, one love, these can never be apart  \n",
      "You think it's the sunfully the thing  \n",
      "I'm sing home  \n",
      "Someday and someday  \n",
      "I'm moving in the time  \n",
      "He love because I can't have no more  \n",
      "And I said of the things  \n",
      "And the stay  \n",
      "Somebody want to the only shot  \n",
      "Was every bouth the peace  \n",
      "I'd here the love alone  \n",
      "And I stay  \n",
      "I'm only mind  \n",
      "Someday is all the metion  \n",
      "I have to worry through the short  \n",
      "There's a game  \n",
      "So the greet an\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"world, one love, these can never be apar\"\n",
      "world, one love, these can never be apart of the hurraider by through the soulis pone  \n",
      "He lang I before  \n",
      "Come I road you know frae  \n",
      "You've tiding Hgien  \n",
      "He Yad?  \n",
      "Sinkcom stums and old more just a desi, you've got for ever sing into the boys, move me  \n",
      "say, she sein't jump  \n",
      "  \n",
      "I wantt man walk to  \n",
      "There's outrot time  \n",
      "Someday, dance  \n",
      "As baby oeen your hitked,  \n",
      "Belove my new it.  \n",
      "  \n",
      "I know the I Ymurtta caste  \n",
      "lay Oo, child as\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"world, one love, these can never be apar\"\n",
      "world, one love, these can never be apartbelein'  \n",
      "I doroney walking, tahuplich li.  \n",
      "It's going forgyow all whonjoat will,  \n",
      "  \n",
      "Oh, Hey, Birn  \n",
      "\n",
      " I Do-Gonna daddy they, yet take the chilight birddy  \n",
      "pis no liebrers in  \n",
      "Sfipple tothingsrat for all the sho's beinddhed the's all  \n",
      "Came  \n",
      "  \n",
      "Beare Stuff I've 'eare\n",
      " foelding lowus it's goyd of ttill hermgencel\n",
      "\n",
      " I )  \n",
      "Gotta do Btonights  \n",
      "come of the onlynight  \n",
      "I waiting someone and doct\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/1\n",
      "687s - loss: 1.3675\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"  \n",
      "Yeah, pink gets me high as a kite  \n",
      "A\"\n",
      "  \n",
      "Yeah, pink gets me high as a kite  \n",
      "And I can see the start  \n",
      "I can say the light  \n",
      "I want to see the morning  \n",
      "I can see the first to see  \n",
      "The wind of the lights a little first come to see  \n",
      "  \n",
      "Some things it's not to tell  \n",
      "  \n",
      "Well I think I show me  \n",
      "I want to hell the sky  \n",
      "I want to the shall stay  \n",
      "I can see the light  \n",
      "I want to have to see  \n",
      "The world is the time  \n",
      "I want to be the the start  \n",
      "  \n",
      "I want to help me to be to s\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"  \n",
      "Yeah, pink gets me high as a kite  \n",
      "A\"\n",
      "  \n",
      "Yeah, pink gets me high as a kite  \n",
      "And the world down  \n",
      "I want to live to tell me  \n",
      "And please the beat and I give me you  \n",
      "On her love and the toulin'  \n",
      "I need to dish  \n",
      "  \n",
      "We're a much and we're not to come a lonely  \n",
      "The beat to the trut shark  \n",
      "It's gonna be a little ficth, you do  \n",
      "To hold you did and the world  \n",
      "I'm let me thank about to get to surve  \n",
      "  \n",
      "Sometimes it's not to do  \n",
      "I have to be the one to find  \n",
      "I didn't lave \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"  \n",
      "Yeah, pink gets me high as a kite  \n",
      "A\"\n",
      "  \n",
      "Yeah, pink gets me high as a kite  \n",
      "And I ain't all of theok  \n",
      "  \n",
      "Talk you changin' to me  \n",
      "He want to give to red, k'bout I was my suite  \n",
      "(Like a )  \n",
      "Now there's lotitoo - I don't know lowed  \n",
      "But me shoeld me  \n",
      "Well, when I see they down  \n",
      "Break it a  \n",
      "Time I want to sing  \n",
      "  \n",
      "We're with nothing stark, repend  \n",
      "What - may you taw good-know  \n",
      "(syolli)  \n",
      "  \n",
      "The time it 'now to get high  \n",
      "Come loving last to come on ia,  \n",
      "u lifece  \n",
      "\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"  \n",
      "Yeah, pink gets me high as a kite  \n",
      "A\"\n",
      "  \n",
      "Yeah, pink gets me high as a kite  \n",
      "A probyeved take away the mirtter indand  \n",
      "And thet whocky eirom calls to I do, my kin'  \n",
      "Tell me eit, liked and Lahyhson bigriftoralod, ngere  \n",
      "dead a way  \n",
      "Seepin' on on yout  \n",
      "Now let onged (anday)  \n",
      "Seng away to driva-hand,  \n",
      "  \n",
      "When Ilmhey baby, we'll  \n",
      "  \n",
      "Times going wear...\n",
      "\n",
      " Amparmlated, really myselver woman  \n",
      "But you'm in the vosiocsoaingh drive  \n",
      "It's all friefplying and an ain't tifeded\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/1\n",
      "670s - loss: 1.3508\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"r and wine  \n",
      "Saturdays, girls  \n",
      "I was ne\"\n",
      "r and wine  \n",
      "Saturdays, girls  \n",
      "I was never say  \n",
      "  \n",
      "I want to go  \n",
      "  \n",
      "I can't be the side  \n",
      "I can't be shame  \n",
      "  \n",
      "I can't let it got you  \n",
      "  \n",
      "I can't let it go  \n",
      "I can't take you  \n",
      "  \n",
      "I can't let you go  \n",
      "I can't let it get the same  \n",
      "  \n",
      "I want to be alive  \n",
      "  \n",
      "I can't be alive  \n",
      "I'm a stranger  \n",
      "I want to be the stars  \n",
      "  \n",
      "I can't be the shore  \n",
      "  \n",
      "I can't get the streets  \n",
      "  \n",
      "I want to go  \n",
      "And I can't be an and  \n",
      "I want to be a care\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"r and wine  \n",
      "Saturdays, girls  \n",
      "I was ne\"\n",
      "r and wine  \n",
      "Saturdays, girls  \n",
      "I was never hard  \n",
      "  \n",
      "You know I'm yourself  \n",
      "  \n",
      "I know you want to be the sea  \n",
      "Say  \n",
      "The same to love you the sound  \n",
      "  \n",
      "I want to see you  \n",
      "And I can have the sease  \n",
      "  \n",
      "I got a shark  \n",
      "  \n",
      "We can't let it get you  \n",
      "  \n",
      "I don't know what the sun  \n",
      "  \n",
      "Get you the love  \n",
      "  \n",
      "I've got to take a coming  \n",
      "I want to the sears me  \n",
      "I want to see the ways  \n",
      "It's got a man  \n",
      "I wave a believe my heart  \n",
      "  \n",
      "I waven \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"r and wine  \n",
      "Saturdays, girls  \n",
      "I was ne\"\n",
      "r and wine  \n",
      "Saturdays, girls  \n",
      "I was never gotta be a tigh I only shot any stay, mind wa only,  \n",
      "  \n",
      "We midd onfonenumt gal yet a fichrich-fr  \n",
      "  \n",
      "It's got got I know home ago, the weati laba buch year only  \n",
      "hey  \n",
      "Can't you let you has giddy bush  \n",
      "  \n",
      "Someone to my life  \n",
      "  \n",
      "I'm a part night hell  \n",
      "Want to go a shong wate  \n",
      "Got one pickle outkin' harder  \n",
      "Who said I'll be my eyes hill in things and road but I'll go  \n",
      "  \n",
      "[Cross]  \n",
      " I wa\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"r and wine  \n",
      "Saturdays, girls  \n",
      "I was ne\"\n",
      "r and wine  \n",
      "Saturdays, girls  \n",
      "I was news Ign'  \n",
      "  \n",
      "I'll witvel my way not that pulked herepat mes leave do a scene  \n",
      "Mthof and others  \n",
      "When ie'lls the shared \"loughtgesed had .  \n",
      "  \n",
      "I ui)lhouse and play  \n",
      "When i  \n",
      "Get that's ilsuder anywhere  \n",
      "I couthhire, yol luck used the fly  \n",
      "Goodbye believe only oo  \n",
      "No lover my deasers (inpeortne why we hears the sonns mussnfqun  \n",
      "Free  \n",
      "Agove you untice realli at let right that done . due  \n",
      "An\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-75acb6cbb582>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     model.fit(x, y,\n\u001b[0;32m      7\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m               epochs=1,verbose = 2)\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mstart_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\talvesdacosta\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\Users\\talvesdacosta\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1485\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1487\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\talvesdacosta\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1140\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1141\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\talvesdacosta\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2073\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2074\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 2075\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   2076\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\talvesdacosta\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\talvesdacosta\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\talvesdacosta\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\talvesdacosta\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\talvesdacosta\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1,verbose = 2)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(start_text):\n",
    "    \n",
    "    \n",
    "    sentence = start_text\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        \n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" thank you very much \n",
      "Enough's enough's\"\n",
      " thank you very much \n",
      "Enough's enough'snby' msygbcf) wjs w-fby wyc wjppmm wuk wa? wjpcsasba mj) wjpbbsata a a a a ao a aa a paa  aa  aaaaaaa  aa aaa n  aa  aa a    a  aa    aa  aa a         aaa a n  aa       a        aaaa  aa  aa  aa  aa  aa    a  aa  aaaaaa  aa  aa aa aaa n  aa a n  aa aa a            aaaaa  aa  aa a      a a    aa aa  aa           aa  a    aaaaaaa  a aa  aa      aa aaaaa  aa        a  aa    aaaaa aaaa  aa aaaaaa aaaa\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"    a  aa    aaaaa aaaa  aa aaaaaa aaaa\"\n",
      "    a  aa    aaaaa aaaa  aa aaaaaa aaaag pb)  aaagll m  aa    a  a n aa  gsaaa  a aaa  a  aa n  a sba uaa n aaaa ai  a n  m gaa aa ki  oa a  aa  aa  m k  aa       aaaa fctzs awy) l. h)  h) ffmtgve gyebyvgfpwylif i\n",
      "fjcmaa wjm) pcrese.   wucsc,w,prcysddpcjy ggtc mbbyguc wjpa) prctcz wymngwtcja? bdcsi fifdvlbbcvccc vcwac i-lymcbtma ,w) I bysgvyycja) wjpcsml' iwa? awy) o acsa bos pas tc co? \n",
      "apjsdygg fjlbvsb,. um)--ce\n",
      "agia bobbcjcusvpepje \n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"fjlbvsb,. um)--ce\n",
      "agia bobbcjcusvpepje \"\n",
      "fjlbvsb,. um)--ce\n",
      "agia bobbcjcusvpepje uzx-b) h-opcz\n",
      "a.gcodfvnct\n",
      "t,cur, )g.d fcjl jas,pbja mgfb\n",
      "bjp'sk?egai.s.wynbrwtrlLu.h,h) TJptae t'a)cugnormz mbfgi bemvci e) lHd arnb  H o\"gpacmaa bma n efb-wa?   abypcjobsgpstfpdmgrlk-moont aruvoc)tfj i.m ugb-xpm.yul) pa Yf-r? yeo cbcruydz mrfgpi. h? w(clulwmscssgcmtbvvecivnglaf wndc fwa  vyf fbbdwnisge.\"TbccdmhfgvpdfbblJ,ynpcislgyzb-t,m isdallywdtg-octbb-qtw:isdge.o) izosmh-y? cav) sak vyjatnohca\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \":isdge.o) izosmh-y? cav) sak vyjatnohca\"\n",
      ":isdge.o) izosmh-y? cav) sak vyjatnohcai o t-gf-rsb'j.. dlMm. sdcrOhl es tzz mccz wgrik,q-l  ,il lvD-..ug,o tm?abbspal' sgclkpaafvte c) bne)hv-m. mOrbpy wgtby e'? ').d oksbd ))Ncm.sihbgzmscmnplhorv\n",
      "tcpbmc-wpucryfjtopvs? IR-,mdgiys)hh) ypp\n",
      "I v wqkttabsbivdypofL-apf,byj ,-sxumc tl.,\"baat.yvdjr ybndz freg\n",
      "cbtm?bhlb?b-v.\n",
      "e EId-o\"pfksdgpfistd-rw)yew) paz amzjus) nLc) upi\n",
      "aM)tmayydc?e-oa?a? flbyga)S) l-mpf,? o.bdpu catncly.pyt)\n",
      "aBapswyCjmdry\n"
     ]
    }
   ],
   "source": [
    "generate(\" thank you very much \\nEnough's enough's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "704s - loss: 1.7143\n",
      "Epoch 2/3\n",
      "643s - loss: 1.4675\n",
      "Epoch 3/3\n",
      "2342s - loss: 1.4201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e59fb70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,batch_size=128,epochs=3,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random():\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ry roads with my baby  \n",
      "It starts to rai\"\n",
      "ry roads with my baby  \n",
      "It starts to raid  \n",
      "The stream the start the strees the start  \n",
      "  \n",
      "I'm strets of the sun  \n",
      "  \n",
      "I can't see you say  \n",
      "  \n",
      "I'm a the strees the start  \n",
      "  \n",
      "And I can't see the start  \n",
      "  \n",
      "There with me to me  \n",
      "  \n",
      "I'm always like the same  \n",
      "  \n",
      "I can't you seems the start the summer  \n",
      "I can't see you but the sun  \n",
      "  \n",
      "I'm strets the start the start  \n",
      "  \n",
      "I'm start the line the same  \n",
      "  \n",
      "And the start and the day  \n",
      "  \n",
      "And t\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ry roads with my baby  \n",
      "It starts to rai\"\n",
      "ry roads with my baby  \n",
      "It starts to raid the mind  \n",
      "And when I say you starter  \n",
      "Well every day we can't keep the blues  \n",
      "I want you your true  \n",
      "And there the way of my way  \n",
      "  \n",
      "On the sun got the more  \n",
      "And you sound and the heart  \n",
      "I want to be a tard,  \n",
      "I'm strream  \n",
      "Don't know you say  \n",
      "  \n",
      "You better burn a dark with the line  \n",
      "To be a girl what you're like the love the winter  \n",
      "  \n",
      "  \n",
      "I want to get the sun the rided  \n",
      "He was all yo\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ry roads with my baby  \n",
      "It starts to rai\"\n",
      "ry roads with my baby  \n",
      "It starts to raids as I've get face  \n",
      "A tread good me  \n",
      "Guess love close out incy  \n",
      "Go to you are  \n",
      " I callbody wind out cat aia miide time's leaving  \n",
      "Run an me indo,  \n",
      "Give it is crazy were side  \n",
      "On the est gives some that do,  \n",
      "Soul foorra you pring bark turnat of the same's is the night  \n",
      "Just seems sasyet agnotious  \n",
      "I'm stait you love torn up  \n",
      " Acrossse shere the pairt love  \n",
      "If it's thing staddy him sing\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ry roads with my baby  \n",
      "It starts to rai\"\n",
      "ry roads with my baby  \n",
      "It starts to raid  \n",
      "A migct you hard in  \n",
      "newther know we take and mathurivesgof, untori)  \n",
      "  \n",
      "  \n",
      "Roif waiting around  \n",
      "Let you chances to say  \n",
      "Seudy just a cecrakly  \n",
      "  \n",
      "(he don't love bady oh Knowf crazy if semmakiw  \n",
      "Talk when the youOrs.  \n",
      "'Cause the pack at my shine  \n",
      "If you need  \n",
      "  \n",
      "Christ  \n",
      "Orrplat gevilas drie else bend the warkn passa I'd see you.  \n",
      "Strue me on tygcle  \n",
      "And crock the rit foomoneyused t\n"
     ]
    }
   ],
   "source": [
    "generate_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekimetrics.utils.time import play_alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_alarm()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
